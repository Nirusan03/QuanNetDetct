{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Nirusan03\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Importing the required files\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter\n",
    "import pennylane as qml\n",
    "from pennylane import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the original dataset.\n",
    "file_path = \"E:\\\\Studies\\\\IIT\\\\4 - Forth Year\\\\Final Year Project\\\\QuanNetDetct\\\\Datasets\\\\Darknet.csv\"\n",
    "darknet_data = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TLS traffic filtered!\n"
     ]
    }
   ],
   "source": [
    "#  Process 1 - Filter TLS-related traffic.\n",
    "tls_ports = [443, 993, 995, 465, 8443]\n",
    "tls_traffic = darknet_data[\n",
    "    (darknet_data['Dst Port'].isin(tls_ports)) &  # Destination port is TLS-related.\n",
    "    (darknet_data['Protocol'] == 6)              # Protocol is TCP.\n",
    "]\n",
    "\n",
    "print(\"TLS traffic filtered!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding Completed!\n"
     ]
    }
   ],
   "source": [
    "#  Process 2 - Encoding the TLS traffic data.\n",
    "\n",
    "# Creating an object of the LabelEncoder class\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Encode string columns\n",
    "for column in tls_traffic.select_dtypes(include=['object']).columns:\n",
    "    # Assign explicitly to avoid warning\n",
    "    encoded_column = label_encoder.fit_transform(tls_traffic[column])\n",
    "    tls_traffic.loc[:, column] = encoded_column\n",
    "\n",
    "print(\"Encoding Completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaling completed!\n"
     ]
    }
   ],
   "source": [
    "# Process 3 - Scaling the TLS traffic data\n",
    "\n",
    "# Step 1: Make a copy of the DataFrame to avoid SettingWithCopyWarning\n",
    "tls_traffic = tls_traffic.copy()\n",
    "\n",
    "# Step 2: Identify Numeric Columns to Scale\n",
    "# Exclude columns that should not be scaled\n",
    "columns_to_exclude = ['Protocol', 'Dst Port']  # Add any additional columns to exclude if needed\n",
    "numeric_columns = tls_traffic.select_dtypes(include=['float64', 'int64']).columns.difference(columns_to_exclude)\n",
    "\n",
    "# Step 3: Check and Replace Invalid Values\n",
    "# Replace infinity values with NaN\n",
    "tls_traffic[numeric_columns] = tls_traffic[numeric_columns].replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "# Fill NaN values with column means\n",
    "tls_traffic[numeric_columns] = tls_traffic[numeric_columns].fillna(tls_traffic[numeric_columns].mean())\n",
    "\n",
    "# Step 4: Scale Only the Selected Numeric Columns\n",
    "scaler = MinMaxScaler()\n",
    "tls_traffic[numeric_columns] = scaler.fit_transform(tls_traffic[numeric_columns])\n",
    "\n",
    "# Print confirmation\n",
    "print(\"Scaling completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution before SMOTE: Counter({0: 11395, 1: 11395, 2: 11395, 3: 11395})\n",
      "Class distribution after SMOTE: Counter({0: 11395, 1: 11395, 2: 11395, 3: 11395})\n"
     ]
    }
   ],
   "source": [
    "# Process 4 - SMOTE Class imbalance\n",
    "\n",
    "# Step 1: Define the target variable and features\n",
    "X = tls_traffic.drop('Label', axis=1)  # Features\n",
    "y = tls_traffic['Label']              # Target\n",
    "\n",
    "# Step 2: Apply SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "X, y = smote.fit_resample(X, y)\n",
    "\n",
    "# Step 3: Combine features and target back into tls_traffic\n",
    "tls_traffic = pd.DataFrame(X, columns=X.columns)\n",
    "tls_traffic['Label'] = y\n",
    "\n",
    "# Step 4: Display class distribution after SMOTE\n",
    "print(\"Class distribution before SMOTE:\", Counter(y))\n",
    "print(\"Class distribution after SMOTE:\", Counter(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Features Based on Correlation with 'Label':\n",
      "Flow Duration             0.142499\n",
      "Fwd Packet Length Max     0.144930\n",
      "Fwd Packet Length Mean    0.159332\n",
      "Fwd Packet Length Std     0.132663\n",
      "Fwd IAT Total             0.143751\n",
      "Bwd IAT Total             0.137290\n",
      "Fwd PSH Flags             0.182089\n",
      "Packet Length Mean        0.107494\n",
      "FIN Flag Count           -0.172478\n",
      "SYN Flag Count           -0.205988\n",
      "Average Packet Size       0.108640\n",
      "Fwd Segment Size Avg      0.159332\n",
      "Subflow Fwd Bytes         0.132347\n",
      "FWD Init Win Bytes        0.265631\n",
      "Bwd Init Win Bytes        0.240076\n",
      "Fwd Seg Size Min          0.486229\n",
      "Name: Label, dtype: float64\n",
      "Feature-selected dataset without Timestamp saved as '5. Feature_Selected_Dataset.csv'\n"
     ]
    }
   ],
   "source": [
    "# Process 5 - Feature Selection.\n",
    "\n",
    "# Define the target variable.\n",
    "target_variable = 'Label'\n",
    "\n",
    "# Calculate the correlation matrix.\n",
    "correlation_matrix = tls_traffic.corr()\n",
    "\n",
    "# Extract correlations with the target variable.\n",
    "target_correlation = correlation_matrix[target_variable].drop(target_variable)\n",
    "\n",
    "# Set a threshold for correlation (absolute value).\n",
    "threshold = 0.1  # Adjust this based on your needs (e.g., 0.1 for weak correlation).\n",
    "\n",
    "# Select features that are strongly correlated with the target.\n",
    "selected_features = target_correlation[abs(target_correlation) > threshold]\n",
    "\n",
    "# Remove identifier columns from the selected features.\n",
    "identifiers = ['Flow ID', 'Src IP']\n",
    "selected_features = selected_features.drop(index=identifiers, errors='ignore')\n",
    "\n",
    "# Print the selected features and their correlation values.\n",
    "print(\"Selected Features Based on Correlation with 'Label':\")\n",
    "print(selected_features)\n",
    "\n",
    "# Update tls_traffic to retain only selected features and the target variable.\n",
    "tls_traffic = tls_traffic[selected_features.index.tolist() + [target_variable]]\n",
    "\n",
    "# Remove 'Timestamp' after feature selection if it's in the dataset.\n",
    "if 'Timestamp' in tls_traffic.columns:\n",
    "    tls_traffic = tls_traffic.drop(columns=['Timestamp'])\n",
    "    print(\"Timestamp feature removed after feature selection!\")\n",
    "\n",
    "# Save the updated dataset for review.\n",
    "tls_traffic.to_csv(\"5. Feature_Selected_Dataset.csv\", index=False)\n",
    "print(\"Feature-selected dataset without Timestamp saved as '5. Feature_Selected_Dataset.csv'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
